% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bootstrap_trendfilter.R
\name{bootstrap_trendfilter}
\alias{bootstrap_trendfilter}
\title{Construct pointwise variability bands via a bootstrap}
\usage{
bootstrap_trendfilter(
  obj,
  lambda_choice,
  x_eval,
  nx_eval,
  bootstrap_algorithm,
  level = 0.95,
  B = 100L,
  return_ensemble = FALSE,
  prune = TRUE,
  mc_cores = parallel::detectCores() - 4
)
}
\arguments{
\item{obj}{An object of class \code{\link[=sure_trendfilter]{sure_tf}} or
\code{\link[=cv_trendfilter]{cv_tf}}.}

\item{lambda_choice}{One of \code{c("lambda_min","lambda_1se")}. The choice
of hyperparameter that is used for optimized trend filtering estimate.
Defaults to \code{lambda_choice = "lambda_min"}.
\itemize{
\item{\code{"lambda_min"}}: The hyperparameter value that minimizes the cross
validation error curve.
\item{\code{"lambda_1se"}}: The largest hyperparameter value with a cross
validation error within 1 standard error of the minimum cross validation
error. This choice therefore favors simpler (i.e. smoother) trend filtering
estimates. The motivation here is essentially Occam's razor: the two models
yield results that are quantitatively very close, so we favor the simpler
model. See Section 7.10 of
\href{https://web.stanford.edu/~hastie/Papers/ESLII.pdf}{Hastie, Tibshirani, and Friedman (2009)}
for more details on the "one-standard-error rule".}}

\item{x_eval}{(Optional) Overrides \code{nx_eval} if passed. A grid of inputs to
evaluate the optimized trend filtering estimate on.}

\item{nx_eval}{Integer. The length of the input grid that the optimized
trend filtering estimate is evaluated on; i.e. if nothing is passed to
\code{x_eval}, then it is defined as
\code{x_eval = seq(min(x), max(x), length = nx_eval)}.}

\item{bootstrap_algorithm}{A string specifying which variation of the
bootstrap to use. One of \code{c("nonparametric","parametric","wild")}. See
details below for recommendations on when each option is appropriate.}

\item{level}{The level of the pointwise variability bands. Defaults to
\code{level = 0.95}.}

\item{B}{The number of bootstrap samples used to estimate the pointwise
variability bands. Defaults to \code{B = 100}.}

\item{return_ensemble}{Logical. If \code{TRUE}, the full trend filtering bootstrap
ensemble is returned as an \mjseqn{n \times B} matrix, less any columns from
post-hoc pruning (see \code{prune} below). Defaults to \code{return_ensemble = FALSE}
to save memory.}

\item{prune}{Logical. If \code{TRUE}, then the trend filtering bootstrap ensemble
is examined for rare instances in which the optimization has stopped at zero
knots (likely erroneously), and removes them from the ensemble that is used
to compute the variability bands. Defaults to \code{prune = TRUE}. Do not change
this unless you know what you are doing!}

\item{mc_cores}{Multi-core computing using the
\code{\link[parallel:parallel-package]{parallel}} package: The number of cores to
utilize. Defaults to the number of cores detected, minus 4.}
}
\value{
An object of class \code{bootstrap_tf}. This is a comprehensive
list containing all of the analysis' important information, data, and
results:
\describe{
\item{bootstrap_lower_band}{Vector of lower bounds for the pointwise
variability bands, evaluated on \code{x_eval}.}
\item{bootstrap_upper_band}{Vector of upper bounds for the pointwise
variability bands, evaluated on \code{x_eval}.}
\item{bootstrap_algorithm}{A string specifying which variation of the
bootstrap was used to obtain the variability bands.}
\item{level}{The level of the pointwise variability bands.}
\item{B}{The number of bootstrap samples used to estimate the pointwise
variability bands.}
\item{tf_bootstrap_ensemble}{If \code{return_ensemble = TRUE}, the full trend
filtering bootstrap ensemble as an \mjseqn{n \times B} matrix, less any
columns from post-hoc pruning (if \code{prune = TRUE}). Else, this will return
\code{NULL}.}
\item{edf_boots}{An integer vector of the estimated number of effective
degrees of freedom of each trend filtering bootstrap estimate. These should
all be relatively close to \code{edf_min}.}
\item{prune}{Logical. If \code{TRUE}, then the trend filtering bootstrap
ensemble is examined for rare instances in which the optimization has
stopped at zero knots (likely erroneously), and removes them from the
ensemble.}
\item{n_pruned}{The number of poorly-converged bootstrap trend filtering
estimates pruned from the ensemble.}
\item{n_iter_boots}{Vector of the number of iterations taken by the ADMM
algorithm before reaching a stopping criterion, for each bootstrap trend
filtering estimate.}
\item{...}{Named elements inherited from \code{obj} --- an object either of class
\code{\link[=sure_trendfilter]{sure_tf}} or \code{\link[=cv_trendfilter]{cv_tf}}.}
}
}
\description{
\loadmathjax See \href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{Politsch et al. (2020a)} for details.
}
\details{
Our recommendations for when to use each of the possible settings
for the \code{bootstrap_algorithm} argument are shown in the table below. See
\href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{Politsch et al. (2020a)} for more details.\tabular{ll}{
   Scenario \tab Uncertainty quantification \cr
   \code{x} is unevenly sampled \tab \code{bootstrap_algorithm = "nonparametric"} \cr
   \code{x} is evenly sampled and reciprocal variances are not available \tab \code{bootstrap_algorithm = "wild"} \cr
   \code{x} is evenly sampled and reciprocal variances are available \tab \code{bootstrap_algorithm = "parametric"} \cr
}


For our purposes, an evenly sampled data set with some discarded pixels
(either sporadically or in large consecutive chunks) is still considered to
be evenly sampled. When the inputs are evenly sampled on a transformed scale,
we recommend transforming to that scale and carrying out the full trend
filtering analysis on that scale. See the example below for a case when the
inputs are evenly sampled on the \code{log10(x)} scale.
}
\examples{
data(quasar_spectrum)
head(spec)

sure_tf <- sure_trendfilter(spec$log10_wavelength, spec$flux, spec$weights)
opt_tf <- bootstrap_trendfilter(sure_tf, bootstrap_algorithm = "parametric")
}
\references{
\bold{Companion references}
\enumerate{
\item{Politsch et al. (2020a).
\href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{
Trend filtering – I. A modern statistical tool for time-domain astronomy and
astronomical spectroscopy}. \emph{MNRAS}, 492(3), p. 4005-4018.} \cr
\item{Politsch et al. (2020b).
\href{https://academic.oup.com/mnras/article/492/3/4019/5704414}{
Trend Filtering – II. Denoising astronomical signals with varying degrees of
smoothness}. \emph{MNRAS}, 492(3), p. 4019-4032.}}

\bold{The Bootstrap and variations}
\enumerate{
\item{Efron and Tibshirani (1986).
\href{https://projecteuclid.org/journals/statistical-science/volume-1/issue-1/Bootstrap-Methods-for-Standard-Errors-Confidence-Intervals-and-Other-Measures/10.1214/ss/1177013815.full}{
Bootstrap Methods for Standard Errors, Confidence Intervals, and Other
Measures of Statistical Accuracy}.
\emph{Statistical Science}, 1(1), p. 54-75.} \cr
\item{Mammen (1993).
\href{https://projecteuclid.org/journals/annals-of-statistics/volume-21/issue-1/Bootstrap-and-Wild-Bootstrap-for-High-Dimensional-Linear-Models/10.1214/aos/1176349025.full}{
Bootstrap and Wild Bootstrap for High Dimensional Linear Models}. \emph{The
Annals of Statistics}, 21(1), p. 255-285.} \cr
\item{Efron (1979).
\href{https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full}{
Bootstrap Methods: Another Look at the Jackknife}.
\emph{The Annals of Statistics}, 7(1), p. 1-26.}}
}
\seealso{
\code{\link[=sure_trendfilter]{sure_trendfilter()}}, \code{\link[=cv_trendfilter]{cv_trendfilter()}}
}
