% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bootstrap.trendfilter.R
\name{bootstrap.trendfilter}
\alias{bootstrap.trendfilter}
\title{Obtain pointwise uncertainty bands by bootstrapping the optimized trend
filtering estimator.}
\usage{
bootstrap.trendfilter(
  obj,
  level = 0.95,
  B = 100L,
  bootstrap.algorithm = c("nonparametric", "parametric", "wild"),
  return.full.ensemble = FALSE,
  prune = TRUE,
  mc.cores = detectCores()
)
}
\arguments{
\item{obj}{An object of class '\link{SURE.trendfilter}' or
'\link{cv.trendfilter}'.}

\item{level}{The level of the pointwise variability bands. Defaults to
\code{level = 0.95}.}

\item{B}{The number of bootstrap samples used to estimate the pointwise
variability bands. Defaults to \code{B = 100}.}

\item{bootstrap.algorithm}{A string specifying which variation of the
bootstrap to use. One of \code{c("nonparametric","parametric","wild")}. See
details below for recommendations on when each option is appropriate.}

\item{return.full.ensemble}{Logical. If \code{TRUE}, the full trend filtering
bootstrap ensemble is returned as an \mjseqn{n \times B} matrix, less
any columns from post-hoc pruning (see \code{prune} below). Defaults to
\code{return.full.ensemble = FALSE}.}

\item{prune}{Logical. If \code{TRUE}, then the trend filtering bootstrap
ensemble is examined for rare instances in which the optimization has
stopped at zero knots (likely erroneously), and removes them from the
ensemble that is used to compute the variability bands. Defaults to \code{TRUE}.
Do not change this unless you know what you are doing!}

\item{mc.cores}{Parallel computing: The number of cores to utilize. Defaults
to the number of cores detected.}
}
\value{
An object of class 'bootstrap.trendfilter'. This is a comprehensive
list containing all of the analysis important information, data, and
results:
\item{x.eval}{(Inherited from \code{obj}) The grid of inputs the optimized trend
filtering estimate was evaluated on.}
\item{tf.estimate}{The trend filtering estimate of the signal, evaluated on
\code{x.eval}.}
\item{tf.standard.errors}{The standard errors of the optimized trend
filtering point estimator.}
\item{bootstrap.lower.band}{Vector of lower bounds for the
pointwise variability bands, evaluated on \code{x.eval}.}
\item{bootstrap.upper.band}{Vector of upper bounds for the
pointwise variability bands, evaluated on \code{x.eval}.}
\item{bootstrap.algorithm}{A string specifying which variation of the
bootstrap was used to obtain the variability bands.}
\item{level}{The level of the pointwise variability bands.}
\item{B}{The number of bootstrap samples used to estimate the pointwise
variability bands.}
\item{tf.bootstrap.ensemble}{If \code{return.full.ensemble = TRUE}, the
full trend filtering bootstrap ensemble as an \mjseqn{n \times B}
matrix, less any columns from post-hoc pruning (if \code{prune = TRUE}).
If \code{return.full.ensemble = FALSE}, then this will return \code{NULL}.}
\item{edf.boots}{An integer vector of the estimated number of effective
degrees of freedom of each trend filtering bootstrap estimate. These should
all be relatively close to \code{edf.min} (below).}
\item{prune}{Logical. If \code{TRUE}, then the trend filtering bootstrap
ensemble is examined for rare instances in which the optimization has
stopped at zero knots (likely erroneously), and removes them from the
ensemble.}
\item{n.pruned}{The number of poorly-converged bootstrap trend filtering
estimates pruned from the ensemble.}
\item{x}{(Inherited from \code{obj}) Vector of observed inputs.}
\item{y}{(Inherited from \code{obj}) Vector of observed outputs.}
\item{weights}{(Inherited from \code{obj}) A vector of weights for the observed
outputs. These are defined as \code{weights = 1 / sigma^2}, where \code{sigma} is a
vector of standard errors of the uncertainty in the output measurements.}
\item{residuals}{(Inherited from \code{obj}) \code{residuals = y - fitted.values}}
\item{k}{(Inherited from \code{obj}) The degree of the trend filtering estimator.}
\item{gammas}{(Inherited from \code{obj}) Vector of hyperparameter values tested
during validation (always returned in descending order).}
\item{gamma.min}{(Inherited from \code{obj}) Hyperparameter value that minimizes
the validation error curve.}
\item{edf}{(Inherited from \code{obj}) Integer vector of effective degrees of
freedom for trend filtering estimators fit during validation.}
\item{edf.min}{(Inherited from \code{obj}) The effective degrees of freedom of the
optimally-tuned trend filtering estimator.}
\item{i.min}{(Inherited from \code{obj}) The index of \code{gammas} that minimizes the
validation error.}
\item{validation.method}{Either \code{"SURE"} or \code{paste0(V,"-fold CV")}.}
\item{errors}{(Inherited from \code{obj}) Vector of hyperparameter validation
errors, inherited from \code{obj} (an object of class 'SURE.trendfilter').}
\item{optimization.params}{(Inherited from \code{obj}) a list of parameters that
control the trend filtering convex optimization.}
\item{n.iter}{(Inherited from \code{obj}) Vector of the number of iterations
needed for the ADMM algorithm to converge within the given tolerance, for
each hyperparameter value. If many of these are exactly equal to \code{max_iter},
then their solutions have not converged with the tolerance specified by
\code{obj_tol}. In which case, it is often prudent to increase \code{max_iter}.}
\item{n.iter.boots}{Vector of the number of iterations needed for the ADMM
algorithm to converge within the given tolerance, for each bootstrap trend
filtering estimate.}
\item{x.scale, y.scale, data.scaled}{For internal use.}
}
\description{
\loadmathjax \code{bootstrap.trendfilter} implements
}
\details{
\loadmathjax See
\href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{
Politsch et al. (2020a)} for more details.

\itemize{
\item{The inputs are irregularly sampled}
\item{The inputs are regularly sampled and the noise distribution is known}
\item{The inputs are regularly sampled and the noise distribution is unknown}
}

Parametric bootstrap for fixed-input uncertainty quantification (when noise
distribution \mjseqn{\epsilon_i\sim Q_i} is known a priori)
Require: Training Data \mjseqn{(x_1, y_1),\dots,(x_n, y_n)}, hyperparameters
\mjseqn{\gamma} and \mjseqn{k}, assumed noise distribution
\mjseqn{\epsilon_i \sim Q_i}, prediction input grid \mjseqn{x_1',\dots,x_m'}
Compute the trend filtering point estimate at the observed inputs:
\mjseqn{(x_1, y_1),\dots, (x_n, y_n)}
For \mjseqn{b in 1:B}
Define a bootstrap sample by sampling from the assumed noise distribution:
\mjsdeqn{y_i = \widehat{f}(x_i) + \epsilon_i \quad \quad \text{where }\epsilon_i \sim Q_i, \quad i=1,\dots,n}
Let \mjseqn{\widehat{f}(x_1'), \dots, \widehat{f}(x_m')} denote the trend
filtering estimate fit on the bootstrap sample and evaluated on the
prediction grid \mjseqn{x_1',\dots,x_m'}

Given the full trend filtering bootstrap ensemble provided by the relevant
bootstrap algorithm, for any \mjseqn{\alpha\in(0,1)}, a
\mjseqn{(1-\alpha)\cdot100}\% pointwise variability band is
given by
\mjsdeqn{B_{1-\alpha}(x_i') = \left(\widehat{f}\emph{{\alpha/2}(x_i'),\;\widehat{f}}{1-\alpha/2}(x_i')\right), \quad\quad i = 1,\dots,m}
where
\mjsdeqn{\widehat{f}\emph{{\beta}(x_i') = \inf}{g}\left\{g : \frac{1}{B} \sum_{b=1}^{B} \mathbbm{1}\big\{\widehat{f}_{b}(x_i') \leq g\big\} \geq \beta \right\}, \quad\quad \beta\in(0,1).}
}
\examples{
data(quasar_spec)

opt <- SURE.trendfilter(spec$log10.wavelength, spec$flux, spec$weights)
boot.out <- bootstrap.trendfilter(SURE.out, bootstrap.algorithm = "parametric")
}
\references{
\bold{Companion references}
\enumerate{
\item{Politsch et al. (2020a).
\href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{
Trend filtering – I. A modern statistical tool for time-domain astronomy and
astronomical spectroscopy}. \emph{MNRAS}, 492(3), p. 4005-4018.} \cr
\item{Politsch et al. (2020b).
\href{https://academic.oup.com/mnras/article/492/3/4019/5704414}{
Trend Filtering – II. Denoising astronomical signals with varying degrees of
smoothness}. \emph{MNRAS}, 492(3), p. 4019-4032.}}

\bold{The Bootstrap and variations}
\enumerate{
\item{Efron and Tibshirani (1986).
\href{https://projecteuclid.org/journals/statistical-science/volume-1/issue-1/Bootstrap-Methods-for-Standard-Errors-Confidence-Intervals-and-Other-Measures/10.1214/ss/1177013815.full}{
Bootstrap Methods for Standard Errors, Confidence Intervals, and Other
Measures of Statistical Accuracy}.
\emph{Statistical Science}, 1(1), p. 54-75.} \cr
\item{Mammen (1993).
\href{https://projecteuclid.org/journals/annals-of-statistics/volume-21/issue-1/Bootstrap-and-Wild-Bootstrap-for-High-Dimensional-Linear-Models/10.1214/aos/1176349025.full}{
Bootstrap and Wild Bootstrap for High Dimensional Linear Models}. \emph{The
Annals of Statistics}, 21(1), p. 255-285.} \cr
\item{Efron (1979).
\href{https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full}{
Bootstrap Methods: Another Look at the Jackknife}.
\emph{The Annals of Statistics}, 7(1), p. 1-26.}}
}
\seealso{
{\link{SURE.trendfilter}}, \code{\link{cv.trendfilter}}
}
\author{
\subsection{\bold{Collin A. Politsch, Ph.D.}}{

Email: collinpolitsch@gmail.com \cr
Website: \href{https://collinpolitsch.com/}{collinpolitsch.com} \cr
GitHub: \href{https://github.com/capolitsch/}{github.com/capolitsch} \cr \cr
}
}
